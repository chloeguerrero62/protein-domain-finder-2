{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Domain Finder 2: End-to-End Pipeline\n",
    "\n",
    "This notebook runs the complete pipeline for protein domain detection as implemented in the chloeguerrero62/protein-domain-finder-2 repository.\n",
    "\n",
    "It covers:\n",
    "- Downloading selected protein PDB structures\n",
    "- Computing distance matrices\n",
    "- Running clustering algorithms (Louvain, Two-Stage Spectral, etc.)\n",
    "- Comparing all methods\n",
    "- Running random controls/ablations\n",
    "- Summarizing results and benchmarking\n",
    "- Visualization\n",
    "\n",
    "*Be sure to have the `src` directory and required dependencies installed! See repo README for setup instructions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Selected PDB Structures\n",
    "---\n",
    "\n",
    "This downloads all PDB files as listed in `data/pdb_clustering/selected_proteins_mmseqs2.csv` into `data/selected_structures`. Requires Biopython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio.PDB import PDBList\n",
    "import os\n",
    "\n",
    "def download_selected_structures(csv_file, output_dir=\"data/selected_structures\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df = pd.read_csv(csv_file)\n",
    "    pdbl = PDBList()\n",
    "    for i, row in df.iterrows():\n",
    "        pdb_id = row['pdb_id'].lower()\n",
    "        print(f\"  [{i+1}/{len(df)}] {pdb_id}\")\n",
    "        try:\n",
    "            pdbl.retrieve_pdb_file(\n",
    "                pdb_id,\n",
    "                pdir=output_dir,\n",
    "                file_format='pdb'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR: {e}\")\n",
    "        \n",
    "# Uncomment to run (requires Biopython and internet)\n",
    "# download_selected_structures(\"data/pdb_clustering/selected_proteins_mmseqs2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Distance Matrices\n",
    "\n",
    "Requires `src/features/structure_parser.py` and `src/features/distance_matrix.py`. Each selected protein’s CA-CA distance matrix is computed and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, str(Path('.').absolute()))\n",
    "from src.features.structure_parser import ProteinStructureParser\n",
    "from src.features.distance_matrix import compute_distance_matrix\n",
    "\n",
    "# Setup output\n",
    "df = pd.read_csv('data/pdb_clustering/selected_proteins_mmseqs2.csv')\n",
    "output_dir = Path('data/distance_matrices')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "parser = ProteinStructureParser(pdb_dir='data/selected_structures')\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    pdb_id = row['pdb_id']\n",
    "    chain_id = row['chain']\n",
    "    pdb_chain = f\"{pdb_id}_{chain_id}\"\n",
    "    print(f\"[{i+1}/{len(df)}] {pdb_chain}...\")\n",
    "    try:\n",
    "        coords, res_ids = parser.parse_structure(pdb_id, chain_id)\n",
    "        D = compute_distance_matrix(coords)\n",
    "        np.save(output_dir / f'{pdb_id}_{chain_id}_distmat.npy', D)\n",
    "        print(\"  ✓ success\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Clustering Methods\n",
    "\n",
    "This section demonstrates unsupervised Louvain clustering and best unsupervised two-stage spectral. (See source scripts for more variants.)\n",
    "\n",
    "*Requires:*\n",
    "- `src/models/louvain_clustering.py`\n",
    "- `src/features/graph_builder.py`\n",
    "- `src/features/structure_parser.py`\n",
    "- `src/features/distance_matrix.py`\n",
    "- `src/evaluation/metrics.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Louvain Clustering Example ---\n",
    "from src.models.louvain_clustering import louvain_clustering, partition_to_labels\n",
    "from src.features.graph_builder import build_knn_graph\n",
    "import pickle\n",
    "\n",
    "louvain_results = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    pdb_id = row['pdb_id']\n",
    "    chain_id = row['chain']\n",
    "    pdb_chain = f\"{pdb_id}_{chain_id}\"\n",
    "    try:\n",
    "        D = np.load(f\"data/distance_matrices/{pdb_id}_{chain_id}_distmat.npy\")\n",
    "        G = build_knn_graph(D, k=10)\n",
    "        partition = louvain_clustering(G, resolution=1.0, random_state=42)\n",
    "        labels = partition_to_labels(partition)\n",
    "        louvain_results[pdb_chain] = labels\n",
    "        np.save(f\"data/clusters/{pdb_chain}_partition.npy\", labels)\n",
    "        with open(f\"data/clusters/{pdb_chain}_partition.pkl\", 'wb') as f:\n",
    "            pickle.dump(partition, f)\n",
    "        print(f\"Louvain done for {pdb_chain}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Louvain error for {pdb_chain}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Two-Stage Spectral Clustering Example (est. n_domains, then spectral) ---\n",
    "from src.evaluation.metrics import compute_all_metrics\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def estimate_domain_count(distance_matrix, method='silhouette', max_domains=8, sigma_factor=1.0):\n",
    "    sigma = np.median(distance_matrix[distance_matrix > 0]) * sigma_factor\n",
    "    similarity = np.exp(-distance_matrix**2 / (2 * sigma**2))\n",
    "    n_residues = len(distance_matrix)\n",
    "    max_k = min(max_domains, n_residues // 10)\n",
    "    best_k, best_score = 2, -1\n",
    "    for k in range(2, max_k + 1):\n",
    "        clustering = SpectralClustering(\n",
    "            n_clusters=k,\n",
    "            affinity='precomputed',\n",
    "            random_state=42,\n",
    "            assign_labels='kmeans'\n",
    "        )\n",
    "        labels = clustering.fit_predict(similarity)\n",
    "        score = silhouette_score(distance_matrix, labels, metric='precomputed')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    return best_k\n",
    "\n",
    "spectral_results = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    pdb_id = row['pdb_id']\n",
    "    chain_id = row['chain']\n",
    "    pdb_chain = f\"{pdb_id}_{chain_id}\"\n",
    "    try:\n",
    "        D = np.load(f\"data/distance_matrices/{pdb_id}_{chain_id}_distmat.npy\")\n",
    "        n_domains = estimate_domain_count(D)\n",
    "        sigma = np.median(D[D > 0])\n",
    "        similarity = np.exp(-D**2 / (2 * sigma**2))\n",
    "        clustering = SpectralClustering(\n",
    "            n_clusters=n_domains,\n",
    "            affinity='precomputed',\n",
    "            random_state=42,\n",
    "            assign_labels='kmeans')\n",
    "        labels = clustering.fit_predict(similarity)\n",
    "        spectral_results[pdb_chain] = labels\n",
    "        np.save(f\"data/results/two_stage_labels/{pdb_chain}_labels.npy\", labels)\n",
    "        print(f\"Spectral done for {pdb_chain}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Spectral error for {pdb_chain}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare All Methods Across Proteins\n",
    "\n",
    "This block runs all methods in a batch and aggregates detailed metrics for analysis. (Simplified demo; see repository for all metrics/functions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block assumes src/evaluation/clustering_comparison.py provides: apply_louvain, apply_spectral_distance, etc.\n",
    "from src.evaluation.clustering_comparison import apply_louvain, apply_spectral_distance, apply_spectral_graph, apply_hierarchical, apply_two_stage_spectral\n",
    "all_results = []\n",
    "parser = ProteinStructureParser(pdb_dir='data/selected_structures')\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    pdb_id = row['pdb_id']\n",
    "    chain_id = row['chain']\n",
    "    n_true = row['n_domains']\n",
    "    try:\n",
    "        coords, _ = parser.parse_structure(pdb_id, chain_id)\n",
    "        D = compute_distance_matrix(coords)\n",
    "        G = build_knn_graph(D, k=10)\n",
    "        # Louvain\n",
    "        labels = apply_louvain(D, G)\n",
    "        metrics = compute_all_metrics(labels, None, n_true)\n",
    "        metrics['method'] = 'Louvain'\n",
    "        # Spectral (distance)\n",
    "        labels = apply_spectral_distance(D, n_true)\n",
    "        metrics2 = compute_all_metrics(labels, None, n_true)\n",
    "        metrics2['method'] = 'Spectral-Distance'\n",
    "        # (add more methods as needed)\n",
    "        all_results.extend([metrics, metrics2])\n",
    "    except Exception as e:\n",
    "        print(f\"Comparison error for {pdb_id}_{chain_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv('data/results/method_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Random Controls and Ablation Studies\n",
    "\n",
    "See `scripts/random_controls.py` for control setup. Example control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assignment_control(n_residues, n_domains, n_trials=10):\n",
    "    errors = []\n",
    "    for _ in range(n_trials):\n",
    "        labels = np.random.randint(0, n_domains, size=n_residues)\n",
    "        error = 0\n",
    "        errors.append(error)\n",
    "    return {\n",
    "        'n_predicted': n_domains,\n",
    "        'mean_error': np.mean(errors),\n",
    "        'method': 'Random-Oracle'\n",
    "    }\n",
    "# Example usage for a protein:\n",
    "row = df.iloc[0]\n",
    "random_assignment_control(row['n_residues'] if 'n_residues' in row else 100, row['n_domains'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summarize Results (Tables)\n",
    "\n",
    "Outputs main comparison/results tables as CSV and console.\n",
    "\n",
    "Requires the results files from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_comp = pd.read_csv('data/results/method_comparison.csv')\n",
    "# Table: Per-method summary\n",
    "tbl = method_comp.groupby(['method']).agg({\n",
    "    'pdb_chain': 'count',\n",
    "    'exact_match': 'sum',\n",
    "    'absolute_error': 'mean',\n",
    "    'n_predicted': 'mean'\n",
    "})\n",
    "tbl.columns = ['N', 'Exact Matches', 'MAE', 'Avg Predicted']\n",
    "tbl['Exact Match %'] = (tbl['Exact Matches'] / tbl['N'] * 100).round(1)\n",
    "print(tbl)\n",
    "tbl.to_csv('data/results/method_summary_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Example Domain Assignments\n",
    "\n",
    "Visualize results for a given protein using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: visualize Louvain assignments for one protein\n",
    "pdb_chain = list(louvain_results.keys())[0]\n",
    "labels = louvain_results[pdb_chain]\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.scatter(range(len(labels)), labels, c=labels, cmap='tab20')\n",
    "plt.title(f'Louvain clustering: {pdb_chain}')\n",
    "plt.xlabel('Residue Position')\n",
    "plt.ylabel('Domain Cluster')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
